[
  {
    "id": 1,
    "question": "What is the main purpose of the SMOTE algorithm in machine learning?",
    "options": [
      "To reduce the number of samples in the majority class",
      "To generate synthetic samples for the minority class to balance imbalanced datasets",
      "To improve model performance by feature scaling",
      "To perform dimensionality reduction using principal components"
    ],
    "correctAnswer": "To generate synthetic samples for the minority class to balance imbalanced datasets",
    "explanation": "SMOTE (Synthetic Minority Over-sampling Technique) is used to balance imbalanced datasets by creating synthetic samples of the minority class through interpolation between existing samples, thus improving model training on less represented classes."
  },
  {
    "id": 2,
    "question": "Given the code snippet: generateData = SMOTE(dataSet[, c(1,2)], dataSet[, c(3)], K=5), what does dataSet[, c(3)] represent?",
    "options": [
      "Features for training",
      "Target or class labels",
      "Indices for data partitioning",
      "Synthetic data generated by SMOTE"
    ],
    "correctAnswer": "Target or class labels",
    "explanation": "In this context, dataSet[, c(3)] selects column 3, which contains the labels or the target variable for the SMOTE oversampling process."
  },
  {
    "id": 3,
    "question": "Which method is a wrapper approach for feature selection?",
    "options": [
      "Pearson correlation",
      "Recursive Feature Elimination (RFE)",
      "Principal Component Analysis (PCA)",
      "Chi-square test"
    ],
    "correctAnswer": "Recursive Feature Elimination (RFE)",
    "explanation": "Wrapper methods involve using the model itself to evaluate subsets of features by training and testing, such as Recursive Feature Elimination which trains models on subsets and selects features based on performance."
  },
  {
    "id": 4,
    "question": "Refer to the table below (from the provided learning material) that compares Pseudonymization and Anonymization. Which statement correctly differentiates the two?\n\n| Aspect            | Pseudonymization                           | Anonymization                     |\n|-------------------|-------------------------------------------|----------------------------------|\n| Linkability       | Possible with additional info (key)       | Not possible                     |\n| Data Utility      | High                                      | Lower due to irreversible masking|\n| Regulatory Status | Still considered personal data             | Not considered personal data      |\n| Reversibility     | Yes (with key)                            | No                               |\n\n",
    "options": [
      "Pseudonymization completely removes all identifying information irreversibly.",
      "Anonymization allows data to be linked back to individuals with a key.",
      "Pseudonymization retains high data utility and is reversible with a key.",
      "Both methods are legally considered non-personal data."
    ],
    "correctAnswer": "Pseudonymization retains high data utility and is reversible with a key.",
    "explanation": "Pseudonymization replaces identifiers with a key that allows re-identification, maintaining high data utility but still considered personal data under regulations. Anonymization is irreversible and data can't be linked back, thus not personal data."
  },
  {
    "id": 5,
    "question": "Which of the following is a potential downside of using open data in data science projects?",
    "options": [
      "Open data always provides complete and bias-free data samples.",
      "Open data can dominate research projects due to its abundance and availability.",
      "Open data requires paid subscriptions and strict licensing.",
      "Open data is always easily accessible and formatted for use."
    ],
    "correctAnswer": "Open data can dominate research projects due to its abundance and availability.",
    "explanation": "While open data is freely accessible, its sheer amount and popularity can bias the focus of data science projects, while accessibility and usability issues may still arise."
  },
  {
    "id": 6,
    "question": "What does the term 'Algorithmic bias' refer to in machine learning?",
    "options": [
      "Errors in data caused by hardware failures",
      "Systematic unfair or discriminatory outputs produced by algorithms due to biased data or design",
      "Intentional manipulation of output to achieve desired results",
      "Random noise in model predictions"
    ],
    "correctAnswer": "Systematic unfair or discriminatory outputs produced by algorithms due to biased data or design",
    "explanation": "Algorithmic bias arises when machine learning models produce outputs that unfairly favor or disadvantage certain groups, often due to skewed training data or flawed design."
  },
  {
    "id": 7,
    "question": "In statistical hypothesis testing, what does a p-value less than 0.05 generally indicate?",
    "options": [
      "There is over 5% probability the null hypothesis is true",
      "There is less than 5% probability that observed results are due to chance if null hypothesis is true",
      "The alternative hypothesis is definitely true",
      "The sample size is too small"
    ],
    "correctAnswer": "There is less than 5% probability that observed results are due to chance if null hypothesis is true",
    "explanation": "A p-value below 0.05 suggests that the observed data would be unlikely under the null hypothesis, leading to its rejection with a 5% significance level."
  },
  {
    "id": 8,
    "question": "The following is a confusion matrix:\n\n|                 | Predicted Positive  | Predicted Negative  |\n|-----------------|---------------------|---------------------|\n| Actual Positive | True Positive (TP)  | False Negative (FN) |\n| Actual Negative | False Positive (FP) | True Negative (TN)  |\n\nWhat does 'False Negative' mean?",
    "options": [
      "Predicting positive when actually negative",
      "Predicting negative when actually positive",
      "Correctly predicting negative",
      "Correctly predicting positive"
    ],
    "correctAnswer": "Predicting negative when actually positive",
    "explanation": "A False Negative occurs when the model incorrectly predicts a negative outcome for a sample that is actually positive."
  },
  {
    "id": 9,
    "question": "Calculate the entropy of a dataset S where 75% of samples belong to class A and 25% belong to class B. Use the formula: Entropy(S) = – ∑ p_i * log2(p_i), where p_i is the class probability.",
    "options": ["0.81", "0.5", "1.0", "0.0"],
    "correctAnswer": "0.81",
    "explanation": "Entropy = –(0.75*log2(0.75) + 0.25*log2(0.25)) = –(0.75*(-0.415) + 0.25*(-2)) = 0.311 + 0.5 = 0.811 bits, approximated as 0.81."
  },
  {
    "id": 10,
    "question": "Refer to the diagram of a Receiver Operating Characteristic (ROC) curve showing True Positive Rate (Sensitivity) vs. False Positive Rate. As you move along the curve by changing the classification threshold, what is the typical trade-off observed?",
    "options": [
      "Increasing sensitivity decreases false positives",
      "Increasing sensitivity increases false positives",
      "False positives remain constant as sensitivity increases",
      "Sensitivity does not depend on threshold"
    ],
    "correctAnswer": "Increasing sensitivity increases false positives",
    "explanation": "Lowering the classification threshold typically increases sensitivity (true positive rate) but also increases the false positive rate, showing the trade-off between catching positives and avoiding false alarms."
  },
  {
    "id": 11,
    "question": "What is the key difference between Bagging and Boosting ensemble methods?",
    "options": [
      "Bagging trains models sequentially focusing on misclassifications; Boosting trains models independently in parallel",
      "Bagging trains models independently in parallel; Boosting trains models sequentially focusing on correcting errors",
      "Both are identical methods that use random forests",
      "Boosting only works for regression tasks"
    ],
    "correctAnswer": "Bagging trains models independently in parallel; Boosting trains models sequentially focusing on correcting errors",
    "explanation": "Bagging reduces variance by training multiple models independently (e.g., random forests), while Boosting trains models sequentially, each correcting errors from the previous."
  },
  {
    "id": 12,
    "question": "Which approach does the Boruta algorithm use for feature selection?",
    "options": [
      "Filter method based on Pearson correlation",
      "Wrapper method using random forests and creating shadow features",
      "Dimensionality reduction using PCA",
      "Embedded method within logistic regression"
    ],
    "correctAnswer": "Wrapper method using random forests and creating shadow features",
    "explanation": "Boruta is a wrapper method that compares real features against shadow features created by permuting the data, using random forests to evaluate feature importance."
  },
  {
    "id": 13,
    "question": "In R, what does the function call 'cor.test(x, y, method = \"pearson\")' accomplish?",
    "options": [
      "Computes a two-sample t-test between vectors x and y",
      "Calculates the Pearson correlation coefficient and tests its significance between x and y",
      "Performs a linear regression of y on x",
      "Computes covariance between x and y"
    ],
    "correctAnswer": "Calculates the Pearson correlation coefficient and tests its significance between x and y",
    "explanation": "cor.test computes the correlation coefficient and performs a hypothesis test whether the correlation is statistically different from zero."
  },
  {
    "id": 14,
    "question": "What is the importance of calculating Variance Inflation Factor (VIF) during regression modeling?",
    "options": [
      "To detect multicollinearity among predictors which can destabilize coefficient estimates",
      "To test the overall fit of the model",
      "To measure the residual errors",
      "To predict dependent variable values"
    ],
    "correctAnswer": "To detect multicollinearity among predictors which can destabilize coefficient estimates",
    "explanation": "VIF quantifies how much a predictor is explained by other predictors, helping identify multicollinearity which affects coefficient interpretability."
  },
  {
    "id": 15,
    "question": "Explain why Adjusted R-squared is preferred over R-squared in multiple regression.",
    "options": [
      "Because R-squared always decreases when adding variables",
      "Because Adjusted R-squared penalizes excessive predictors and prevents overfitting",
      "Adjusted R-squared is easier to compute",
      "They are interchangeable"
    ],
    "correctAnswer": "Because Adjusted R-squared penalizes excessive predictors and prevents overfitting",
    "explanation": "Adjusted R-squared accounts for the number of predictors, increasing only if a new variable improves the model beyond chance, unlike R-squared which always increases with more variables."
  },
  {
    "id": 16,
    "question": "Given the logistic regression coefficient for the variable 'FirstRun' is 0.2, how do you interpret the odds ratio?",
    "options": [
      "Exp(0.2) ≈ 1.22, meaning each unit increase in FirstRun increases odds by about 22%",
      "Odds decrease by 20% for unit increase in FirstRun",
      "The variable is not significant",
      "The coefficient is in probability units"
    ],
    "correctAnswer": "Exp(0.2) ≈ 1.22, meaning each unit increase in FirstRun increases odds by about 22%",
    "explanation": "In logistic regression, coefficients are log odds. Exponentiating gives the odds ratio. 1.22 means a unit increase raises the odds by 22%."
  },
  {
    "id": 17,
    "question": "Refer to the following time series plot of monthly airline passengers and accompanying correlogram (autocorrelation function) and partial autocorrelation function (PACF). The ACF shows a slow decay, and the PACF cuts off sharply after lag 1. Which time series model is most appropriate?\n\n ![Plot of monthly airline passengers, ACF of monthly airline passengers, PACF of monthly airline passengers](/assets/acf-pacf.png)",
    "options": ["AR(1) model", "MA(1) model", "ARMA(1,1) model", "White noise"],
    "correctAnswer": "AR(1) model",
    "explanation": "A slow decay in ACF combined with a sharp cutoff after lag 1 in PACF typically suggests an autoregressive model of order 1 (AR(1))."
  },
  {
    "id": 18,
    "question": "What does the Augmented Dickey-Fuller (ADF) test evaluate?",
    "options": [
      "Whether time series data is non-stationary or stationary",
      "The presence of seasonality in data",
      "The best ARIMA model order",
      "Random noise level"
    ],
    "correctAnswer": "Whether time series data is non-stationary or stationary",
    "explanation": "The ADF test's null hypothesis is that the series has a unit root (non-stationary); rejection suggests stationarity, crucial for time series modeling."
  },
  {
    "id": 19,
    "question": "Describe the purpose and typical result of applying first order differencing to non-stationary time series data.",
    "options": [
      "It smoothes the series by averaging data over intervals",
      "It removes trend components leading to stationarized data",
      "It filters out seasonal effects entirely",
      "It increases data variance"
    ],
    "correctAnswer": "It removes trend components leading to stationarized data",
    "explanation": "First order differencing subtracts each observation from its predecessor, eliminating trends and helping achieve stationarity needed for ARIMA modeling."
  },
  {
    "id": 20,
    "question": "Explain the difference between sensitivity and specificity in binary classification.",
    "options": [
      "Sensitivity measures true negatives, specificity measures true positives",
      "Sensitivity measures the proportion of actual positives correctly identified, specificity measures the proportion of actual negatives correctly identified",
      "Both measure true positives but under different thresholds",
      "They are inverses"
    ],
    "correctAnswer": "Sensitivity measures the proportion of actual positives correctly identified, specificity measures the proportion of actual negatives correctly identified",
    "explanation": "Sensitivity (also called recall) focuses on detecting positives, while specificity focuses on correctly identifying negatives."
  },
  {
    "id": 21,
    "question": "Refer to the plotted boxplot diagram showing distribution of runner times. If the median line falls near the lower edge of the box, what does it indicate about the skewness of the data?\n\n ![boxplot diagram here](/assets/box-plot.png)",
    "options": [
      "Data is symmetrically distributed",
      "Data is skewed to the left (negatively skewed)",
      "Data is skewed to the right (positively skewed)",
      "Information insufficient"
    ],
    "correctAnswer": "Data is skewed to the right (positively skewed)",
    "explanation": "When the median is closer to the lower hinge, the right side has a longer tail, indicating positive (right) skewness."
  },
  {
    "id": 22,
    "question": "In the context of text mining, what is tokenization?",
    "options": [
      "Removing punctuation from text",
      "Breaking down text into individual words or tokens",
      "Converting words to their root forms",
      "Removing common 'stop' words"
    ],
    "correctAnswer": "Breaking down text into individual words or tokens",
    "explanation": "Tokenization splits text into meaningful units (usually words) for further analysis."
  },
  {
    "id": 23,
    "question": "What are stop words in natural language processing, and why are they removed?",
    "options": [
      "Common words like 'the' and 'and' removed to reduce noise and dimensionality",
      "Rare words removed due to low significance",
      "Misspelled words removed",
      "Proper nouns removed for privacy"
    ],
    "correctAnswer": "Common words like 'the' and 'and' removed to reduce noise and dimensionality",
    "explanation": "Stop words are high-frequency common words that provide little discriminative value and are thus excluded to improve analysis efficiency."
  },
  {
    "id": 24,
    "question": "In R, what is the purpose of the DocumentTermMatrix function in the tm package?",
    "options": [
      "To convert corpus text data into a matrix showing term frequencies across documents",
      "To perform stemming on words",
      "To remove stop words",
      "To plot word clouds"
    ],
    "correctAnswer": "To convert corpus text data into a matrix showing term frequencies across documents",
    "explanation": "DocumentTermMatrix creates a sparse matrix where each row is a document and each column is a term, indicating the frequency of terms per document."
  },
  {
    "id": 25,
    "question": "Explain the concept of TF-IDF in text analysis.",
    "options": [
      "It measures the frequency of a term in the entire corpus",
      "It weights terms by their frequency in a document but reduces weight for terms common across documents",
      "It selects only the most frequent terms",
      "It assigns equal weights to all terms"
    ],
    "correctAnswer": "It weights terms by their frequency in a document but reduces weight for terms common across documents",
    "explanation": "Term Frequency - Inverse Document Frequency (TF-IDF) increases the importance of terms frequent in a document but rare across corpus, highlighting distinctive words."
  },
  {
    "id": 26,
    "question": "Which statement correctly describes k-Nearest Neighbors (k-NN)?",
    "options": [
      "It is an eager learning method that builds a model during training",
      "It is a lazy learning method that waits until prediction time to classify",
      "It reduces dimensionality before classification",
      "It is only used for regression tasks"
    ],
    "correctAnswer": "It is a lazy learning method that waits until prediction time to classify",
    "explanation": "k-NN stores all data and uses the closest k data points to classify a new instance at prediction time without building an explicit model."
  },
  {
    "id": 27,
    "question": "Given a dataset with a severe class imbalance, which technique is NOT typically used to address this?",
    "options": [
      "Under-sampling the majority class",
      "Over-sampling the minority class",
      "Applying SMOTE to generate synthetic minority samples",
      "Simply increasing the number of features"
    ],
    "correctAnswer": "Simply increasing the number of features",
    "explanation": "Increasing feature dimensionality does not solve class imbalance and may worsen model performance; balancing techniques focus on adjusting class distributions."
  },
  {
    "id": 28,
    "question": "What key ethics principles should be considered when designing user interfaces with persuasive design techniques?",
    "options": [
      "User benefit and transparency",
      "Deceptiveness and manipulation",
      "Maximizing data collection at all costs",
      "Avoiding user consent"
    ],
    "correctAnswer": "User benefit and transparency",
    "explanation": "Persuasive design should benefit users and be transparent to respect user autonomy and avoid manipulative dark patterns."
  },
  {
    "id": 29,
    "question": "Refer to the following diagram of a K-fold cross-validation process. What is the primary advantage of this technique over a simple train-test split?\n\n ![cross-validation diagram here](/assets/k-fold.png)",
    "options": [
      "It always uses more data for training, reducing overfitting",
      "It assesses model performance variability by testing on multiple folds",
      "It is computationally inexpensive",
      "It ignores class imbalance"
    ],
    "correctAnswer": "It assesses model performance variability by testing on multiple folds",
    "explanation": "K-fold CV partitions data into multiple folds, rotating through them as test sets, providing a more reliable estimate of performance and variance than a single split."
  },
  {
    "id": 30,
    "question": "Write R code to calculate the Euclidean distance between two numeric vectors: a = c(2,3,5), b = c(1,1,1)",
    "options": [
      "sqrt(sum((a - b)^2))",
      "sum((a - b)^2)",
      "cor(a, b)",
      "mean(abs(a - b))"
    ],
    "correctAnswer": "sqrt(sum((a - b)^2))",
    "explanation": "Euclidean distance is calculated as the square root of the sum of squared differences between corresponding vector elements."
  },
  {
    "id": 31,
    "question": "Explain the meaning and cause of the 'file drawer effect' in scientific research.",
    "options": [
      "Publication bias where only positive or significant results are published, skewing available evidence",
      "Data imputation method for missing values",
      "The tendency to overfit models with too many features",
      "Error in randomness due to small sample sizes"
    ],
    "correctAnswer": "Publication bias where only positive or significant results are published, skewing available evidence",
    "explanation": "Studies yielding non-significant results often remain unpublished ('filed away'), leading to distorted meta-analyses and inflated perceptions of effects."
  },
  {
    "id": 32,
    "question": "What does the term 'overfitting' mean in machine learning?",
    "options": [
      "When a model learns the training data too well, including noise, and performs poorly on new data",
      "When a model performs equally well on training and test data",
      "Only training on a large dataset",
      "Using a model too simple for the problem"
    ],
    "correctAnswer": "When a model learns the training data too well, including noise, and performs poorly on new data",
    "explanation": "Overfitting results in low bias but high variance, causing poor generalization to unseen data."
  },
  {
    "id": 33,
    "question": "What is the purpose of the Shapiro-Wilk test in statistics?",
    "options": [
      "To test normality of a data sample",
      "To test for homoscedasticity",
      "To test independence of variables",
      "To compare two proportions"
    ],
    "correctAnswer": "To test normality of a data sample",
    "explanation": "The Shapiro-Wilk test evaluates the null hypothesis that a sample is drawn from a normally distributed population."
  },
  {
    "id": 34,
    "question": "In the context of machine learning, what is 'concept drift'?",
    "options": [
      "When the model forgets training data",
      "When the statistical properties of the target variable change over time, reducing model performance",
      "Scaling of data incorrectly",
      "Using improper loss function"
    ],
    "correctAnswer": "When the statistical properties of the target variable change over time, reducing model performance",
    "explanation": "Concept drift describes shifts in data patterns that models fail to anticipate, requiring retraining or adaptation."
  },
  {
    "id": 35,
    "question": "Describe the difference between 'lazy learning' and 'eager learning' algorithms with examples.",
    "options": [
      "Lazy learning builds a model upfront; eager learning delays prediction until data arrives (e.g., KNN is eager, Decision Trees are lazy).",
      "Lazy learning waits until prediction time to model (e.g., KNN), while eager learning builds models during training (e.g., Decision Trees, SVM).",
      "They are synonyms.",
      "Lazy learning requires less computation during prediction."
    ],
    "correctAnswer": "Lazy learning waits until prediction time to model (e.g., KNN), while eager learning builds models during training (e.g., Decision Trees, SVM).",
    "explanation": "Lazy learners store data and compute predictions on demand, while eager learners generalize from data during training and quickly predict new samples."
  },
  {
    "id": 36,
    "question": "In survival analysis, what does a Kaplan-Meier plot represent?",
    "options": [
      "Probability of survival over time for one or more groups",
      "Rate of occurrence of an event",
      "Linear regression fitting over time",
      "Histogram of survival times"
    ],
    "correctAnswer": "Probability of survival over time for one or more groups",
    "explanation": "Kaplan-Meier estimates the survival function, graphing the proportion surviving beyond given times, often comparing treatments."
  },
  {
    "id": 37,
    "question": "When would you prefer a paired t-test over an unpaired t-test?",
    "options": [
      "When comparing means of two independent groups",
      "When comparing means of the same subjects measured twice",
      "When testing for correlation",
      "When comparing variances"
    ],
    "correctAnswer": "When comparing means of the same subjects measured twice",
    "explanation": "A paired t-test accounts for the dependence between paired observations (e.g., before and after treatment on same subjects)."
  },
  {
    "id": 38,
    "question": "Explain the difference between precision and recall in classification.",
    "options": [
      "Precision measures how many selected items are relevant; recall measures how many relevant items are selected.",
      "Precision measures false negatives; recall measures false positives.",
      "They are identical metrics",
      "Precision is always greater than recall"
    ],
    "correctAnswer": "Precision measures how many selected items are relevant; recall measures how many relevant items are selected.",
    "explanation": "Precision = TP / (TP + FP), recall = TP / (TP + FN). Precision focuses on accuracy of positive predictions; recall focuses on coverage of actual positives."
  },
  {
    "id": 39,
    "question": "Provide an example R code snippet to perform a 10-fold cross-validation using the caret package for decision tree training.",
    "options": [
      "control <- trainControl(method = \"cv\", number = 10)\nmodel <- train(target ~ ., data = trainingData, method = \"rpart\", trControl = control)",
      "trainControl(\"cv\", folds = 10)\ntrain(model, data)",
      "cv10 <- trainControl(nfold = 10)\nc50(model, data = trainingData, control = cv10)",
      "No built-in way in caret for cross-validation"
    ],
    "correctAnswer": "control <- trainControl(method = \"cv\", number = 10)\nmodel <- train(target ~ ., data = trainingData, method = \"rpart\", trControl = control)",
    "explanation": "The caret package uses trainControl to specify cross-validation with method='cv' and number of folds, then trains the model with this control."
  },
  {
    "id": 40,
    "question": "Which of the following best describes the Law of Large Numbers in statistics?",
    "options": [
      "Sample mean converges to population mean as sample size increases",
      "Sample variance increases with sample size",
      "Probability decreases with more trials",
      "The larger the sample, the greater the expected error"
    ],
    "correctAnswer": "Sample mean converges to population mean as sample size increases",
    "explanation": "The Law of Large Numbers states that as the sample size grows, the sample average tends to get closer to the expected value."
  },
  {
    "id": 41,
    "question": "Refer to the diagram showing a decision tree structure with root, branches, and leaves. What main criterion is used by decision trees for splitting nodes?",
    "options": [
      "Information Gain, based on entropy reduction",
      "Random selection of features",
      "Euclidean distance minimization",
      "Gradient descent"
    ],
    "correctAnswer": "Information Gain, based on entropy reduction",
    "explanation": "Decision trees split on features that yield the greatest information gain, reducing uncertainty (entropy) about the class labels."
  },
  {
    "id": 42,
    "question": "What is the meaning of 'pseudo-replication' in statistical analyses and why it is problematic?",
    "options": [
      "Treating non-independent data points as independent, inflating sample size and risking false significance",
      "Repeating analyses multiple times with different data",
      "Using bootstrapping to estimate statistics",
      "Pooling data from multiple studies"
    ],
    "correctAnswer": "Treating non-independent data points as independent, inflating sample size and risking false significance",
    "explanation": "Pseudo-replication leads to artificially reduced variance and increased Type I errors by ignoring data dependencies."
  },
  {
    "id": 43,
    "question": "What kind of features are called 'independent' when using Pearson correlation for feature selection?",
    "options": [
      "Features highly correlated with each other",
      "Features uncorrelated with each other but correlated with the target variable",
      "Features not correlated with the target variable",
      "Features that are categorical"
    ],
    "correctAnswer": "Features uncorrelated with each other but correlated with the target variable",
    "explanation": "Selecting independent features means choosing those that provide unique information for prediction, i.e., not redundant with one another but relevant to the output."
  },
  {
    "id": 44,
    "question": "In the R code for standardizing numerical features: 'IrisData$SepalLengthCm <- scale(IrisData$SepalLengthCm)', what do the 'scale' function do?",
    "options": [
      "Normalizes data to range [^1]",
      "Substracts mean and divides by standard deviation, producing standardized features",
      "Converts data to factors",
      "Performs Principal Component Analysis"
    ],
    "correctAnswer": "Substracts mean and divides by standard deviation, producing standardized features",
    "explanation": "scale() centers and scales data, yielding features with zero mean and unit variance, useful for many ML algorithms."
  },
  {
    "id": 45,
    "question": "Explain the term 'confounding' in the context of data analysis.",
    "options": [
      "A variable that distorts the apparent effect of an explanatory variable on the outcome",
      "Random noise in data",
      "Missing values that reduce power",
      "Interaction effects between variables"
    ],
    "correctAnswer": "A variable that distorts the apparent effect of an explanatory variable on the outcome",
    "explanation": "Confounders can bias estimated relationships and mislead causal inference if they are not controlled."
  },
  {
    "id": 46,
    "question": "Explain why the Balanced Accuracy metric is preferred over simple Accuracy in imbalanced classification problems.",
    "options": [
      "Balanced Accuracy averages sensitivity and specificity, giving fair evaluation even when classes are uneven",
      "Balanced Accuracy ignores true negatives",
      "Accuracy always overestimates model quality",
      "Balanced Accuracy is simpler to compute"
    ],
    "correctAnswer": "Balanced Accuracy averages sensitivity and specificity, giving fair evaluation even when classes are uneven",
    "explanation": "Simple accuracy can be misleading when majority class dominates; balanced accuracy accounts equally for both classes."
  },
  {
    "id": 47,
    "question": "Which R package is commonly used for survival analysis including functions like survfit and Kaplan-Meier plots?",
    "options": ["survival", "caret", "tm", "randomForest"],
    "correctAnswer": "survival",
    "explanation": "The 'survival' package provides extensive functionality for survival analysis in R, including Kaplan-Meier estimation and log-rank tests."
  },
  {
    "id": 48,
    "question": "What is the ethical concern with 'dark patterns' in User Interface (UI) design?",
    "options": [
      "They improve user experience transparently",
      "They intentionally manipulate users for business gains at user's expense without consent",
      "They mandate accessibility standards",
      "They simplify user decisions"
    ],
    "correctAnswer": "They intentionally manipulate users for business gains at user's expense without consent",
    "explanation": "Dark patterns trick users into actions they might not otherwise take, violating ethical UI design principles."
  },
  {
    "id": 49,
    "question": "What is the difference between 'discretization' and 'quantization' in data preprocessing?",
    "options": [
      "Discretization is the process of creating a continuous variable from a categorical one, quantization is the opposite.",
      "Both refer to dividing continuous variables into intervals or bins, often used interchangeably",
      "Discretization applies only to images, quantization only to time series",
      "Quantization increases variable range"
    ],
    "correctAnswer": "Both refer to dividing continuous variables into intervals or bins, often used interchangeably",
    "explanation": "Both terms describe breaking continuous data into discrete bins for modelling or visualization purposes."
  },
  {
    "id": 50,
    "question": "Describe the function of AUC (Area Under the Curve) in ROC analysis.",
    "options": [
      "Quantifies the aggregate measure of performance across all classification thresholds",
      "Measures model training time",
      "Identifies optimal cutoff value directly",
      "Measures correlation between features"
    ],
    "correctAnswer": "Quantifies the aggregate measure of performance across all classification thresholds",
    "explanation": "AUC summarizes true positive rate vs false positive rate trade-offs across thresholds; higher AUC indicates better discrimination."
  },
  {
    "id": 51,
    "question": "What is the Synthetic Minority Over-sampling Technique (SMOTE) primarily used for in machine learning?",
    "options": [
      "Reducing dimensionality of features",
      "Balancing class distribution by generating synthetic minority class samples",
      "Encoding categorical variables",
      "Improving model interpretability"
    ],
    "correctAnswer": "Balancing class distribution by generating synthetic minority class samples",
    "explanation": "SMOTE creates new synthetic samples of the minority class by interpolating between existing minority samples to address dataset imbalance, improving model learning on underrepresented classes."
  },
  {
    "id": 52,
    "question": "Given the R code snippet: `generateData = SMOTE(dataSet[, c(1, 2)], dataSet[, c(3)], K=5)`, what is the role of the parameter K=5?",
    "options": [
      "Number of nearest neighbors to use for synthetic sample generation",
      "Number of features included",
      "Number of classes in the dataset",
      "Number of times SMOTE runs"
    ],
    "correctAnswer": "Number of nearest neighbors to use for synthetic sample generation",
    "explanation": "The parameter K specifies the number of nearest neighbors considered for interpolating new minority class samples."
  },
  {
    "id": 53,
    "question": "Refer to the following simplified diagram of a decision tree split on a continuous variable:\n\n ![diagram showing root node splitting feature X <= 5](/assets/node_split.png) \n\nWhat criterion is commonly used to select the splitting point in decision trees?",
    "options": [
      "Correlation coefficient",
      "Information gain or reduction in entropy",
      "Euclidean distance",
      "Logistic regression coefficient"
    ],
    "correctAnswer": "Information gain or reduction in entropy",
    "explanation": "Decision trees use criteria such as Information Gain, calculated by entropy reduction, to identify the best feature and threshold to split the data maximizing purity."
  },
  {
    "id": 54,
    "question": "What does the term 'pseudo-replication' mean in statistical analyses and why is it problematic?",
    "options": [
      "Treating non-independent data points as independent, inflating sample size and risking false positives",
      "Repeated measures design",
      "Using bootstrap methods",
      "Pooling datasets from multiple studies"
    ],
    "correctAnswer": "Treating non-independent data points as independent, inflating sample size and risking false positives",
    "explanation": "Pseudo-replication falsely inflates the effective sample size by ignoring dependencies between observations, increasing the chance of Type I errors."
  },
  {
    "id": 55,
    "question": "Describe the primary difference between Pseudonymization and Anonymization of data according to the table:\n\n| Aspect       | Pseudonymization                      | Anonymization                  |\n|--------------|-------------------------------------|-------------------------------|\n| Linkability  | Possible with additional info (key) | Not possible                  |\n| Data Utility | High                                | Lower due to irreversible masking |\n| Reversibility| Yes (with key)                      | No                            |\n\nWhich statement is correct?",
    "options": [
      "Anonymization retains reversible linking to original data",
      "Pseudonymization is irreversible",
      "Pseudonymization retains data utility and reversibility with a key",
      "Both are considered equally personal data under GDPR"
    ],
    "correctAnswer": "Pseudonymization retains data utility and reversibility with a key",
    "explanation": "Pseudonymization replaces identifiers but keeps the ability to re-identify using a key, maintaining higher data utility while anonymization irreversibly removes identifiers."
  },
  {
    "id": 56,
    "question": "Refer to this confusion matrix diagram:\n\n|                 | Predicted Positive | Predicted Negative |\n|-----------------|--------------------|--------------------|\n| Actual Positive | True Positive (TP)  | False Negative (FN) |\n| Actual Negative | False Positive (FP) | True Negative (TN)  |\n\nWhat type of error is represented by False Positive (FP)?",
    "options": [
      "Correctly predicting positive cases",
      "Predicting negative when actual is positive",
      "Predicting positive when actual is negative",
      "Correctly predicting negative cases"
    ],
    "correctAnswer": "Predicting positive when actual is negative",
    "explanation": "A False Positive occurs when the prediction is positive but the actual class is negative, a type I error."
  },
  {
    "id": 57,
    "question": "Calculate the entropy of a dataset with two classes where 90% of samples belong to class A and 10% to class B. Use formula: Entropy = -∑ p_i log2(p_i).",
    "options": ["0.469", "0.325", "0.9", "1.0"],
    "correctAnswer": "0.469",
    "explanation": "Entropy = - (0.9*log2(0.9) + 0.1*log2(0.1)) = -[0.9*(-0.152) + 0.1*(-3.322)] = 0.137 + 0.332 = 0.469 bits."
  },
  {
    "id": 58,
    "question": "Refer to the ROC curve diagram showing True Positive Rate versus False Positive Rate. What is indicated by an Area Under the Curve (AUC) close to 0.5? \n ![ROC curve diagram showing True Positive Rate versus False Positive Rate](/assets/roc-curve-TPR-FPR.png)\n\n",
    "options": [
      "Perfect classification model",
      "A worthless model performing like random guessing",
      "Model with high sensitivity and specificity",
      "Overfitting to the training data"
    ],
    "correctAnswer": "A worthless model performing like random guessing",
    "explanation": "An AUC of 0.5 indicates the model has no discrimination power and performs no better than random chance."
  },
  {
    "id": 59,
    "question": "Which feature selection approach uses a model to evaluate subsets of features by recursively removing least important features?",
    "options": [
      "Filter method",
      "Wrapper method – Recursive Feature Elimination (RFE)",
      "Embedded method – Lasso regression",
      "Dimensionality reduction – PCA"
    ],
    "correctAnswer": "Wrapper method – Recursive Feature Elimination (RFE)",
    "explanation": "RFE repeatedly trains models, removing the least important features until an optimal subset is identified."
  },
  {
    "id": 60,
    "question": "What does the term ‘reproducibility’ mean in data science research?",
    "options": [
      "Ability to obtain consistent results using the same methods and data",
      "Using different data to confirm findings",
      "Sharing all data publicly",
      "Using multiple models"
    ],
    "correctAnswer": "Ability to obtain consistent results using the same methods and data",
    "explanation": "Reproducibility ensures scientific validity and credibility."
  },
  {
    "id": 61,
    "question": "What is the purpose of the Variance Inflation Factor (VIF) in multiple regression analysis?",
    "options": [
      "To detect heteroscedasticity",
      "To identify predictors that are highly collinear",
      "To assess model fit",
      "To measure residual variance"
    ],
    "correctAnswer": "To identify predictors that are highly collinear",
    "explanation": "VIF quantifies the extent to which one predictor is correlated with other predictors, helping to diagnose multicollinearity issues."
  },
  {
    "id": 62,
    "question": "What does a Shapiro-Wilk test p-value > 0.05 imply about a dataset?",
    "options": [
      "Data significantly deviates from normality",
      "Data is consistent with normal distribution",
      "Test is invalid",
      "Data contains outliers"
    ],
    "correctAnswer": "Data is consistent with normal distribution",
    "explanation": "A high p-value indicates that there's no significant evidence against the null hypothesis of normality."
  },
  {
    "id": 63,
    "question": "Explain the difference between sensitivity and specificity in a binary classification problem.",
    "options": [
      "Sensitivity is the proportion of actual negatives correctly identified; specificity is actual positives",
      "Sensitivity measures how well positives are identified; specificity how well negatives are identified",
      "Both measure false positive rate",
      "They are unrelated metrics"
    ],
    "correctAnswer": "Sensitivity measures how well positives are identified; specificity how well negatives are identified",
    "explanation": "Sensitivity (recall) measures correctly identified positives; specificity measures correctly identified negatives."
  },
  {
    "id": 64,
    "question": "In R, what does the function call `cor.test(x, y, method = \"pearson\")` compute?",
    "options": [
      "Linear regression of y on x",
      "Correlation coefficient and significance test between x and y",
      "Mean difference between x and y",
      "Covariance matrix"
    ],
    "correctAnswer": "Correlation coefficient and significance test between x and y",
    "explanation": "cor.test returns the Pearson correlation coefficient and a p-value testing the hypothesis of no correlation."
  },
  {
    "id": 65,
    "question": "Describe the primary difference between bagging and boosting ensemble methods.",
    "options": [
      "Bagging trains models independently in parallel; boosting trains sequentially focusing on correcting errors",
      "Boosting models run in parallel; bagging uses sequential training",
      "Both reduce bias equally",
      "They are the same"
    ],
    "correctAnswer": "Bagging trains models independently in parallel; boosting trains sequentially focusing on correcting errors",
    "explanation": "Bagging mainly reduces variance; boosting reduces bias and variance by focusing on misclassified instances."
  },
  {
    "id": 66,
    "question": "What is tokenization in text mining?",
    "options": [
      "Combining several words into a phrase",
      "Splitting text into discrete tokens or words",
      "Removing stop words",
      "Converting text to uppercase"
    ],
    "correctAnswer": "Splitting text into discrete tokens or words",
    "explanation": "Tokenization breaks down text into individual words or meaningful units for analysis."
  },
  {
    "id": 67,
    "question": "Explain what stop words are and why they are removed in natural language processing (NLP).",
    "options": [
      "Rare words removed for simplicity",
      "Commonly used words that add little meaning, removed to reduce noise",
      "Misspelled words",
      "Proper nouns"
    ],
    "correctAnswer": "Commonly used words that add little meaning, removed to reduce noise",
    "explanation": "Stop words like 'the', 'and' are frequent but carry little semantic content, so removing them improves NLP efficiency."
  },
  {
    "id": 68,
    "question": "In text analysis, what does the DocumentTermMatrix function in R do?",
    "options": [
      "Removes stop words from text",
      "Creates a matrix of term frequencies per document",
      "Generates word clouds",
      "Performs stemming"
    ],
    "correctAnswer": "Creates a matrix of term frequencies per document",
    "explanation": "It constructs a sparse matrix where rows represent documents and columns represent terms with counts."
  },
  {
    "id": 69,
    "question": "What does the TF-IDF weighting scheme in text mining represent?",
    "options": [
      "Raw count of word occurrences",
      "Term frequency scaled down by inverse document frequency to highlight important words",
      "Binary presence of words",
      "Normalization of word lengths"
    ],
    "correctAnswer": "Term frequency scaled down by inverse document frequency to highlight important words",
    "explanation": "TF-IDF boosts terms frequent in a document but rare across documents, capturing relevance."
  },
  {
    "id": 70,
    "question": "How does the k-Nearest Neighbors (k-NN) algorithm classify a new instance?",
    "options": [
      "Using a pre-built model fitted during training",
      "By majority vote of k nearest neighbors in feature space",
      "By calculating Euclidean distance to class centroids",
      "Using decision trees"
    ],
    "correctAnswer": "By majority vote of k nearest neighbors in feature space",
    "explanation": "k-NN is a lazy learner that classifies based on the classes of nearby points at prediction time."
  },
  {
    "id": 71,
    "question": "Which of these methods is NOT a typical way to handle class imbalance?",
    "options": [
      "Under-sampling the majority class",
      "Over-sampling the minority class",
      "Using SMOTE to generate synthetic samples",
      "Increasing the number of features"
    ],
    "correctAnswer": "Increasing the number of features",
    "explanation": "Increasing features does not address imbalance and may worsen model performance."
  },
  {
    "id": 72,
    "question": "What is 'algorithmic bias' in machine learning?",
    "options": [
      "Random errors caused by data noise",
      "Systematic unfair or discriminatory model predictions due to biased data or design",
      "Intentional algorithm manipulation",
      "Loss of model accuracy during training"
    ],
    "correctAnswer": "Systematic unfair or discriminatory model predictions due to biased data or design",
    "explanation": "Algorithmic bias occurs when model outputs unwittingly disadvantage certain groups because of biased training data or algorithm structure."
  },
  {
    "id": 73,
    "question": "What is the 'file drawer effect' in scientific research?",
    "options": [
      "Loss of experimental data during transfers",
      "Bias where negative or non-significant results remain unpublished",
      "Systematic error from mislabeling data",
      "Outdated methodologies discarded unfairly"
    ],
    "correctAnswer": "Bias where negative or non-significant results remain unpublished",
    "explanation": "Published literature is skewed toward positive findings because non-significant studies are often not reported."
  },
  {
    "id": 74,
    "question": "Refer to this plot of a ROC curve with threshold points marked:\n\n ![ROC curve diagram](/assets/threshold.png) \n\nWhat is the effect of lowering the classification threshold on threshold-dependent metrics?",
    "options": [
      "Sensitivity decreases, False Positive Rate decreases",
      "Sensitivity increases, False Positive Rate increases",
      "Both sensitivity and specificity increase",
      "No effect on sensitivity"
    ],
    "correctAnswer": "Sensitivity increases, False Positive Rate increases",
    "explanation": "Lower thresholds typically classify more items as positive, improving sensitivity but increasing false positives."
  },
  {
    "id": 75,
    "question": "What is the main disadvantage of using a very high value of K in k-NN classifiers?",
    "options": [
      "Overfitting the training data",
      "Increased sensitivity to noise",
      "Underfitting by oversmoothing decision boundaries",
      "High computational cost during training"
    ],
    "correctAnswer": "Underfitting by oversmoothing decision boundaries",
    "explanation": "High K values can obscure finer distinctions between classes, leading to underfitting."
  },
  {
    "id": 76,
    "question": "Explain the concept of 'concept drift' in machine learning.",
    "options": [
      "When model loses training data",
      "Changing statistical properties of target variable over time causing degraded model performance",
      "Scaling data inconsistently",
      "Non-random missing data"
    ],
    "correctAnswer": "Changing statistical properties of target variable over time causing degraded model performance",
    "explanation": "Concept drift happens when relationships between inputs and outputs evolve, necessitating model updates."
  },
  {
    "id": 77,
    "question": "Describe the key difference between bagging and boosting ensemble methods.",
    "options": [
      "Bagging uses sequential training focusing on misclassified samples; boosting trains models independently",
      "Bagging trains models independently in parallel; boosting trains sequentially focusing on correcting errors",
      "Both train models sequentially",
      "Boosting only applies to regression"
    ],
    "correctAnswer": "Bagging trains models independently in parallel; boosting trains sequentially focusing on correcting errors",
    "explanation": "Bagging reduces variance by averaging independent models; boosting sequentially fits models on residuals to reduce bias."
  },
  {
    "id": 78,
    "question": "How does the Boruta algorithm select important features?",
    "options": [
      "Uses Pearson correlation to remove correlated features",
      "Creates shadow features and compares their importance using Random Forests",
      "Applies PCA for dimensionality reduction",
      "Embedded selection during logistic regression"
    ],
    "correctAnswer": "Creates shadow features and compares their importance using Random Forests",
    "explanation": "Boruta iteratively evaluates whether real features outperform random shadow features, deeming the former important."
  },
  {
    "id": 79,
    "question": "Given a logistic regression coefficient of 0.405 for a variable, what is the interpretation of the odds ratio?",
    "options": [
      "Odds increase by 40.5% for one unit increase",
      "Odds decrease by 40.5%",
      "Coefficient has no meaningful interpretation",
      "Odds ratio is 0.405"
    ],
    "correctAnswer": "Odds increase by 40.5% for one unit increase",
    "explanation": "Exponentiate coefficient: exp(0.405) ≈ 1.5, meaning odds increase 50% (approx 40.5%) per unit increase."
  },
  {
    "id": 80,
    "question": "In time series analysis, what does differencing do?",
    "options": [
      "Adds seasonality",
      "Removes trend to make series stationary",
      "Normalizes data",
      "Increases variance"
    ],
    "correctAnswer": "Removes trend to make series stationary",
    "explanation": "Differencing subtracts previous observations to eliminate trends and stabilize the mean."
  },
  {
    "id": 81,
    "question": "What is the general purpose of hyperparameter tuning in machine learning?",
    "options": [
      "To find the best configuration of model parameters to optimize performance",
      "To clean the dataset",
      "To create features",
      "None of the above"
    ],
    "correctAnswer": "To find the best configuration of model parameters to optimize performance",
    "explanation": "Hyperparameter tuning improves model generalization by adjusting settings like K in KNN or learning rate."
  },
  {
    "id": 82,
    "question": "What is the Law of Large Numbers in statistics?",
    "options": [
      "Sample mean tends to population mean as sample size increases",
      "Variance grows with larger samples",
      "Probability decreases as trials increase",
      "Sample error grows with sample size"
    ],
    "correctAnswer": "Sample mean tends to population mean as sample size increases",
    "explanation": "LLN guarantees that with enough samples, the average converges to expected value."
  },
  {
    "id": 83,
    "question": "Explain the difference between Adjusted R-squared and R-squared in regression analysis.",
    "options": [
      "R-squared decreases with more variables, Adjusted R-squared increases",
      "Adjusted R-squared accounts for number of predictors, penalizing overly complex models",
      "No difference",
      "Adjusted R-squared measures residuals only"
    ],
    "correctAnswer": "Adjusted R-squared accounts for number of predictors, penalizing overly complex models",
    "explanation": "Adjusted R-squared increases only if additional variables improve model beyond chance, preventing overfitting."
  },
  {
    "id": 84,
    "question": "What ethical issue do 'dark patterns' in user interface design raise?",
    "options": [
      "Transparent design benefiting users",
      "Manipulative design tricking users into unintended actions",
      "Mandatory accessibility standards",
      "Open source software sharing"
    ],
    "correctAnswer": "Manipulative design tricking users into unintended actions",
    "explanation": "Dark patterns deceive or coerce users for business advantage, violating ethical design."
  },
  {
    "id": 85,
    "question": "In text mining, explain the concept of stemming.",
    "options": [
      "Removing noise from data",
      "Reducing words to their root form by cutting suffixes",
      "Converting documents to matrices",
      "Removing stopwords"
    ],
    "correctAnswer": "Reducing words to their root form by cutting suffixes",
    "explanation": "Stemming simplifies words to base forms to reduce vocabulary size but may sometimes over-truncate."
  },
  {
    "id": 86,
    "question": "What is the key difference between lazy learning and eager learning algorithms?",
    "options": [
      "Lazy learning builds models ahead; eager learning waits to predict",
      "Lazy learning waits until prediction time to compute; eager learning builds model during training",
      "Both build models during training",
      "Lazy learning is only unsupervised methods"
    ],
    "correctAnswer": "Lazy learning waits until prediction time to compute; eager learning builds model during training",
    "explanation": "Lazy learners like k-NN delay model building; eager learners like decision trees build models upfront."
  },
  {
    "id": 87,
    "question": "What R package provides robust survival analysis including Kaplan-Meier plots?",
    "options": ["caret", "survival", "tm", "randomForest"],
    "correctAnswer": "survival",
    "explanation": "The survival package offers tools for time-to-event data analysis, including survfit and Kaplan-Meier estimation."
  },
  {
    "id": 88,
    "question": "Explain the difference between precision and recall with formulas.",
    "options": [
      "Precision = TP/(TP+FP), Recall = TP/(TP+FN)",
      "Precision = TP/(TP+FN), Recall = TP/(TP+FP)",
      "Precision and recall are the same",
      "Precision measures negatives, recall measures positives"
    ],
    "correctAnswer": "Precision = TP/(TP+FP), Recall = TP/(TP+FN)",
    "explanation": "Precision measures accuracy of positive predictions, recall measures ability to find all positive instances."
  },
  {
    "id": 89,
    "question": "Provide an R code snippet to perform a 10-fold cross-validation on a decision tree using the caret package.",
    "options": [
      "control <- trainControl(method = \"cv\", number = 10)\nmodel <- train(target ~ ., data = trainingData, method = \"rpart\", trControl = control)",
      "trainControl(\"cv\", folds = 10)\ntrain(model, data)",
      "cv10 <- trainControl(nfold = 10)\nc50(model, data = trainingData, control = cv10)",
      "crossval <- cv.tree(model, K=10)"
    ],
    "correctAnswer": "control <- trainControl(method = \"cv\", number = 10)\nmodel <- train(target ~ ., data = trainingData, method = \"rpart\", trControl = control)",
    "explanation": "caret uses trainControl to specify cross-validation, then train() to build the model."
  },
  {
    "id": 90,
    "question": "What is the main assumption behind the Central Limit Theorem (CLT)?",
    "options": [
      "Samples must be normally distributed",
      "Samples must be independent and identically distributed with finite variance",
      "Sample size is less than 30",
      "Population mean is unknown"
    ],
    "correctAnswer": "Samples must be independent and identically distributed with finite variance",
    "explanation": "CLT states sums or averages of samples from any distribution converge in distribution to a normal distribution as sample size grows, assuming independence and finite variance."
  },
  {
    "id": 91,
    "question": "Describe the concept of 'multicollinearity' in regression analysis.",
    "options": [
      "Predictor variables are completely independent",
      "Predictors are highly correlated, causing unstable coefficient estimates",
      "Outcome variable is binary",
      "Residuals follow a normal distribution"
    ],
    "correctAnswer": "Predictors are highly correlated, causing unstable coefficient estimates",
    "explanation": "Multicollinearity inflates variance of parameter estimates, making them unreliable."
  },
  {
    "id": 92,
    "question": "Why should feature selection be performed only on training data?",
    "options": [
      "To prevent data leakage and ensure unbiased model evaluation",
      "Because test data features are irrelevant",
      "To simplify computation",
      "No reason; it can be done on entire dataset"
    ],
    "correctAnswer": "To prevent data leakage and ensure unbiased model evaluation",
    "explanation": "Selecting features using test data contaminates model with outside information, biasing performance metrics."
  },
  {
    "id": 93,
    "question": "What is the primary advantage of use of ensemble learning methods like Random Forests?",
    "options": [
      "They reduce variance by averaging many decision trees trained on bootstrapped data",
      "They always perform worse than single decision trees",
      "Only useful for regression",
      "Require no parameter tuning"
    ],
    "correctAnswer": "They reduce variance by averaging many decision trees trained on bootstrapped data",
    "explanation": "Ensembling aggregates multiple models to improve prediction stability and accuracy."
  },
  {
    "id": 94,
    "question": "What is the impact of class imbalance on machine learning classifiers?",
    "options": [
      "Models perform equally well on all classes",
      "Models may bias predictions toward the majority class, ignoring minority",
      "Improves model precision",
      "Not a concern"
    ],
    "correctAnswer": "Models may bias predictions toward the majority class, ignoring minority",
    "explanation": "Class imbalance often leads to poor recognition of minority class due to biased training."
  },
  {
    "id": 95,
    "question": "In survival analysis, what is the primary information depicted in a Kaplan-Meier curve?",
    "options": [
      "Hazard rate over time",
      "Probability of survival as a function of time",
      "Regression coefficient estimates",
      "Cumulative incidence of an event"
    ],
    "correctAnswer": "Probability of survival as a function of time",
    "explanation": "Kaplan-Meier estimates and plots the survival function, illustrating survival probability over time."
  },
  {
    "id": 96,
    "question": "In hypothesis testing, what does a p-value less than 0.05 generally signify?",
    "options": [
      "Accept the null hypothesis",
      "Reject the null hypothesis; results are statistically significant",
      "Sample size is too small",
      "Data is normally distributed"
    ],
    "correctAnswer": "Reject the null hypothesis; results are statistically significant",
    "explanation": "A p-value below threshold suggests low probability results occurred by chance if null true."
  },
  {
    "id": 97,
    "question": "What is the typical effect of outliers on correlation analysis?",
    "options": [
      "No effect",
      "May severely distort correlation coefficients",
      "Always increase correlation",
      "Always decrease correlation"
    ],
    "correctAnswer": "May severely distort correlation coefficients",
    "explanation": "Outliers can inflate or deflate correlation, misrepresenting true relationship."
  },
  {
    "id": 98,
    "question": "What is the difference between supervised and unsupervised learning?",
    "options": [
      "Supervised learning uses labeled data; unsupervised uses unlabeled data to find structure",
      "Unsupervised uses labeled data; supervised uses unlabeled data",
      "Both always require labeled data",
      "No difference"
    ],
    "correctAnswer": "Supervised learning uses labeled data; unsupervised uses unlabeled data to find structure",
    "explanation": "Supervised learning predicts labels; unsupervised learns data patterns without labels."
  },
  {
    "id": 99,
    "question": "What does the R function `lm()` perform?",
    "options": [
      "Principal component analysis",
      "Linear regression modeling",
      "Logistic regression",
      "k-NN classification"
    ],
    "correctAnswer": "Linear regression modeling",
    "explanation": "`lm()` fits linear models predicting a continuous response from explanatory variables."
  },
  {
    "id": 100,
    "question": "Explain the concept of the 'black box' problem in machine learning models.",
    "options": [
      "Models whose inner workings are transparent and easily interpretable",
      "Models that are difficult to interpret or explain even though they produce predictions",
      "Simple algorithms with few parameters",
      "Open source models"
    ],
    "correctAnswer": "Models that are difficult to interpret or explain even though they produce predictions",
    "explanation": "Complex models like deep neural networks often lack interpretability, making understanding decisions difficult."
  },
  {
    "id": 101,
    "question": "Which of the following best describes the main stages of the data science lifecycle?",
    "options": [
      "Data collection, data cleaning, model deployment",
      "Data collection, data cleaning, exploratory data analysis, model building, and deployment",
      "Only data cleaning and model building",
      "Data engineering, feature engineering, testing"
    ],
    "correctAnswer": "Data collection, data cleaning, exploratory data analysis, model building, and deployment",
    "explanation": "The data science lifecycle typically involves collecting data, cleaning and preprocessing data, performing exploratory analysis, building and validating models, then deploying solutions."
  },
  {
    "id": 102,
    "question": "In R, which function is used to check the structure and data types of a dataset 'df'?",
    "options": ["summary(df)", "str(df)", "head(df)", "dim(df)"],
    "correctAnswer": "str(df)",
    "explanation": "The str() function shows the internal structure of an R object including data types of columns and first few entries."
  },
  {
    "id": 103,
    "question": "Which of the following is a continuous random variable?",
    "options": [
      "Number of students in a classroom",
      "Weight of a person",
      "Number of cars in a parking lot",
      "Number of heads in coin flips"
    ],
    "correctAnswer": "Weight of a person",
    "explanation": "Weight is continuous as it can take any value within a range, unlike counts which are discrete."
  },
  {
    "id": 104,
    "question": "What does the Shapiro-Wilk test evaluate in a given dataset?",
    "options": [
      "Whether the data follows a normal distribution",
      "Linearity between two variables",
      "Independence of observations",
      "Equality of variances"
    ],
    "correctAnswer": "Whether the data follows a normal distribution",
    "explanation": "The Shapiro-Wilk test checks the null hypothesis that the data is normally distributed."
  },
  {
    "id": 105,
    "question": "In R, which function can be used to compute the Pearson correlation coefficient and perform a significance test?",
    "options": ["cor.test()", "lm()", "t.test()", "summary()"],
    "correctAnswer": "cor.test()",
    "explanation": "cor.test() returns correlation statistics and p-value for testing no correlation."
  },
  {
    "id": 106,
    "question": "In hypothesis testing, what does a p-value < 0.05 signify?",
    "options": [
      "The null hypothesis is accepted",
      "The null hypothesis can be rejected with 95% confidence",
      "The alternative hypothesis is false",
      "There is a 5% chance of observing the data"
    ],
    "correctAnswer": "The null hypothesis can be rejected with 95% confidence",
    "explanation": "A p-value less than 0.05 indicates sufficient evidence to reject the null hypothesis at the 5% significance level."
  },
  {
    "id": 107,
    "question": "What is the main difference between paired and independent t-tests?",
    "options": [
      "Paired t-test compares groups with related samples; independent t-test compares unrelated groups",
      "Paired t-test compares more than two groups; independent t-test compares two",
      "Paired t-test for large samples; independent for small samples",
      "No difference"
    ],
    "correctAnswer": "Paired t-test compares groups with related samples; independent t-test compares unrelated groups",
    "explanation": "Paired t-tests are used when samples are matched or from the same subjects measured twice."
  },
  {
    "id": 108,
    "question": "What does the Pearson correlation coefficient quantify?",
    "options": [
      "The strength of a linear relationship between two variables",
      "The difference between means",
      "Causation between variables",
      "The variance of one variable"
    ],
    "correctAnswer": "The strength of a linear relationship between two variables",
    "explanation": "Pearson correlation measures the linear association and ranges between -1 and +1."
  },
  {
    "id": 109,
    "question": "What is the purpose of the Variance Inflation Factor (VIF) in regression?",
    "options": [
      "Detect multicollinearity among predictors",
      "Measure overall model accuracy",
      "Test normality of residuals",
      "Detect heteroscedasticity"
    ],
    "correctAnswer": "Detect multicollinearity among predictors",
    "explanation": "VIF values indicate how much the variance of a regression coefficient is inflated due to correlation with other predictors."
  },
  {
    "id": 110,
    "question": "Which of these metrics is most appropriate for assessing model performance on imbalanced classes?",
    "options": [
      "Balanced accuracy",
      "Simple accuracy",
      "Sum of residuals",
      "Mean squared error"
    ],
    "correctAnswer": "Balanced accuracy",
    "explanation": "Balanced accuracy accounts for class imbalance by averaging sensitivity and specificity."
  },
  {
    "id": 111,
    "question": "In logistic regression, a coefficient of 0.4 corresponds approximately to an odds ratio of what?",
    "options": ["1.5", "0.4", "2.5", "0.9"],
    "correctAnswer": "1.5",
    "explanation": "Odds ratio is calculated as exp(coefficient). Here exp(0.4) ≈ 1.5, indicating a 50% increase in odds per unit increase."
  },
  {
    "id": 112,
    "question": "What is the key advantage of using k-fold cross-validation?",
    "options": [
      "It reduces overfitting by evaluating model on multiple train-test splits",
      "It increases dataset size",
      "It simplifies final model building",
      "It eliminates the need for test data"
    ],
    "correctAnswer": "It reduces overfitting by evaluating model on multiple train-test splits",
    "explanation": "K-fold CV assesses model performance across k different subsets to ensure generalizability."
  },
  {
    "id": 113,
    "question": "In R, which package is commonly used for survival analysis?",
    "options": ["survival", "caret", "tm", "randomForest"],
    "correctAnswer": "survival",
    "explanation": "The 'survival' package offers functions like survfit and Kaplan-Meier plotting."
  },
  {
    "id": 114,
    "question": "Explain the difference between sensitivity and specificity in classification tasks.",
    "options": [
      "Sensitivity measures true positive rate; specificity measures true negative rate",
      "Both measure false positive rate",
      "Sensitivity measures precision; specificity measures recall",
      "They are the same"
    ],
    "correctAnswer": "Sensitivity measures true positive rate; specificity measures true negative rate",
    "explanation": "Sensitivity is the proportion of positives correctly identified; specificity is the proportion of negatives correctly identified."
  },
  {
    "id": 115,
    "question": "Refer to the confusion matrix below:\n\n| Actual \\ Predicted | Positive | Negative |\n|--------------------|----------|----------|\n| Positive           | TP       | FN       |\n| Negative           | FP       | TN       |\n\nWhat does ‘False Negative’ mean in this context?",
    "options": [
      "Incorrectly predicting negative when true is positive",
      "Correctly predicting negative",
      "Incorrectly predicting positive when true is negative",
      "Correctly predicting positive"
    ],
    "correctAnswer": "Incorrectly predicting negative when true is positive",
    "explanation": "False Negative errors happen when positive cases are missed (i.e., predicted as negative)."
  },
  {
    "id": 116,
    "question": "What is SMOTE primarily used for in supervised machine learning?",
    "options": [
      "Dimensionality reduction",
      "Balancing imbalanced datasets by generating synthetic minority samples",
      "Feature scaling",
      "Improving feature interpretability"
    ],
    "correctAnswer": "Balancing imbalanced datasets by generating synthetic minority samples",
    "explanation": "SMOTE synthetically generates new minority class samples to balance class distribution."
  },
  {
    "id": 117,
    "question": "Which R function standardizes variables by subtracting the mean and dividing by standard deviation?",
    "options": ["scale()", "normalize()", "center()", "standardize()"],
    "correctAnswer": "scale()",
    "explanation": "The scale() function in R centers and scales data, resulting in zero-mean and unit-variance variables."
  },
  {
    "id": 118,
    "question": "In feature selection, what does the Boruta algorithm do?",
    "options": [
      "Filters features based on p-values only",
      "Uses Random Forest to compare actual features with shadow features to pick important ones",
      "Performs PCA to reduce dimensions",
      "Uses manual selection of variables"
    ],
    "correctAnswer": "Uses Random Forest to compare actual features with shadow features to pick important ones",
    "explanation": "Boruta creates random shadow features to identify those features with statistically significant importance."
  },
  {
    "id": 119,
    "question": "Which of the following ethical issues arises from ‘dark patterns’ in user interface design?",
    "options": [
      "Improving user understanding",
      "Manipulation of users to take unintended actions",
      "Supporting data privacy",
      "Enhancing accessibility"
    ],
    "correctAnswer": "Manipulation of users to take unintended actions",
    "explanation": "Dark patterns deceive or coerce users, violating ethical principles."
  },
  {
    "id": 120,
    "question": "What does the General Data Protection Regulation (GDPR) principle of ‘data minimization’ refer to?",
    "options": [
      "Collecting and processing only necessary personal data",
      "Storing data indefinitely",
      "Sharing data without consent",
      "Deleting all data immediately"
    ],
    "correctAnswer": "Collecting and processing only necessary personal data",
    "explanation": "Data minimization requires organizations to limit data collection to what is strictly needed."
  },
  {
    "id": 121,
    "question": "Define ‘concept drift’ in machine learning.",
    "options": [
      "Model forgetting previous training data",
      "Change in data distribution over time affecting model performance",
      "Hyperparameter tuning technique",
      "Using outdated datasets"
    ],
    "correctAnswer": "Change in data distribution over time affecting model performance",
    "explanation": "Concept drift occurs when underlying relationships evolve, requiring model updates."
  },
  {
    "id": 122,
    "question": "In topic modeling, what does Latent Dirichlet Allocation (LDA) do?",
    "options": [
      "Clusters documents based on explicit labels",
      "Discovers hidden topics by analyzing word co-occurrences",
      "Removes stopwords from documents",
      "Performs sentiment analysis"
    ],
    "correctAnswer": "Discovers hidden topics by analyzing word co-occurrences",
    "explanation": "LDA is a generative probabilistic model that identifies latent topics in text corpora."
  },
  {
    "id": 123,
    "question": "What does the term ‘tokenization’ mean in text mining?",
    "options": [
      "Splitting text into words or tokens",
      "Removing punctuation",
      "Converting text to lowercase",
      "Lemmatizing words"
    ],
    "correctAnswer": "Splitting text into words or tokens",
    "explanation": "Tokenization breaks down text into discrete units for NLP processing."
  },
  {
    "id": 124,
    "question": "What is the benefit of using term frequency-inverse document frequency (TF-IDF) in text analysis?",
    "options": [
      "Emphasizes common words in all documents",
      "Highlights terms important to individual documents relative to the corpus",
      "Ignores rare words",
      "Removes punctuation"
    ],
    "correctAnswer": "Highlights terms important to individual documents relative to the corpus",
    "explanation": "TF-IDF weights terms higher if common in specific documents but rare overall."
  },
  {
    "id": 125,
    "question": "What is the primary goal when tuning hyperparameters in machine learning models?",
    "options": [
      "Maximize model interpretability",
      "Improve predictive performance on unseen data",
      "Reduce dataset size",
      "Increase training time"
    ],
    "correctAnswer": "Improve predictive performance on unseen data",
    "explanation": "Choosing optimal hyperparameters helps the model generalize better and avoid overfitting."
  },
  {
    "id": 126,
    "question": "Which of the following R packages is commonly used for ML model training and parameter tuning?",
    "options": ["caret", "ggplot2", "tm", "survival"],
    "correctAnswer": "caret",
    "explanation": "The caret package provides a unified interface to train ML models and perform hyperparameter tuning."
  },
  {
    "id": 127,
    "question": "Explain the 'file drawer effect' in the context of scientific research.",
    "options": [
      "Publishing all studies regardless of outcome",
      "Non-significant results often remain unpublished, biasing literature",
      "Reproducibility of experiments",
      "Data sharing among researchers"
    ],
    "correctAnswer": "Non-significant results often remain unpublished, biasing literature",
    "explanation": "The file drawer effect occurs when studies with null findings don't get published, skewing perceived evidence."
  },
  {
    "id": 128,
    "question": "What R function would you use to perform a one-sample t-test?",
    "options": ["t.test()", "lm()", "cor.test()", "anova()"],
    "correctAnswer": "t.test()",
    "explanation": "t.test() can be used for one-sample, two-sample, paired, and unpaired tests."
  },
  {
    "id": 129,
    "question": "In R, how would you check for missing values in a vector 'x'?",
    "options": ["is.na(x)", "is.nan(x)", "anyNA(x)", "allNA(x)"],
    "correctAnswer": "is.na(x)",
    "explanation": "is.na() returns TRUE for each element that is NA or NaN, indicating missing values."
  },
  {
    "id": 130,
    "question": "What does the 'Confounding' variable mean in statistical analyses?",
    "options": [
      "A factor that distorts the apparent association between predictor and outcome",
      "An outlier value",
      "A missing value in the dataset",
      "A variable with a linear relationship"
    ],
    "correctAnswer": "A factor that distorts the apparent association between predictor and outcome",
    "explanation": "Confounders can bias estimates unless controlled."
  },
  {
    "id": 131,
    "question": "What best describes the concept of ‘data provenance’?",
    "options": [
      "History of the data lifecycle, including collection, processing, and transformations",
      "Data corruption",
      "Encryption",
      "User privacy settings"
    ],
    "correctAnswer": "History of the data lifecycle, including collection, processing, and transformations",
    "explanation": "Provenance helps ensure data traceability and reproducibility."
  },
  {
    "id": 132,
    "question": "What is the primary purpose of Exploratory Data Analysis (EDA)?",
    "options": [
      "To build predictive models",
      "To summarize main characteristics of data often using visual methods",
      "To clean data automatically",
      "To conduct hypothesis testing"
    ],
    "correctAnswer": "To summarize main characteristics of data often using visual methods",
    "explanation": "EDA helps understand data distributions, patterns, and anomalies before formal modeling."
  },
  {
    "id": 133,
    "question": "What is a limitation of using R-squared as a sole metric for regression model fit?",
    "options": [
      "It always increases when predictors are added, regardless of their usefulness",
      "It is difficult to compute",
      "It is only valid for logistic regression",
      "It measures residual errors poorly"
    ],
    "correctAnswer": "It always increases when predictors are added, regardless of their usefulness",
    "explanation": "R-squared can increase with additional variables even if they do not improve the model, possibly leading to overfitting."
  },
  {
    "id": 134,
    "question": "What is the ethical concern behind algorithmic bias in AI and ML?",
    "options": [
      "It results in unfair or discriminatory outcomes for certain groups",
      "It increases computational cost",
      "It leads to faster model training",
      "It improves model interpretability"
    ],
    "correctAnswer": "It results in unfair or discriminatory outcomes for certain groups",
    "explanation": "Bias in data or design can cause models to reinforce social inequalities."
  },
  {
    "id": 135,
    "question": "What type of learning is k-Nearest Neighbors (k-NN) considered?",
    "options": [
      "Lazy learning",
      "Eager learning",
      "Supervised deep learning",
      "Unsupervised clustering"
    ],
    "correctAnswer": "Lazy learning",
    "explanation": "k-NN delays generalization until prediction time, using data directly for classification."
  },
  {
    "id": 136,
    "question": "In R, which function creates a Document-Term Matrix useful for text mining?",
    "options": [
      "DocumentTermMatrix()",
      "corpus()",
      "wordcloud()",
      "list.files()"
    ],
    "correctAnswer": "DocumentTermMatrix()",
    "explanation": "It creates a sparse matrix representing term frequencies across documents."
  },
  {
    "id": 137,
    "question": "What is one key benefit of synthetic data like that generated by SMOTE in data science?",
    "options": [
      "Helps balance datasets to improve model training on minority classes",
      "Removes all personal data from datasets",
      "Reduces dataset size",
      "Guarantees no data bias"
    ],
    "correctAnswer": "Helps balance datasets to improve model training on minority classes",
    "explanation": "Synthetic samples alleviate class imbalance without losing real samples."
  },
  {
    "id": 138,
    "question": "Explain the law of large numbers in statistics.",
    "options": [
      "As sample size increases, sample mean converges to true population mean",
      "Sample variance always increases with sample size",
      "Probability of errors increases with samples",
      "Population mean decreases with large samples"
    ],
    "correctAnswer": "As sample size increases, sample mean converges to true population mean",
    "explanation": "LLN guarantees consistency of sample averages with population parameters."
  },
  {
    "id": 139,
    "question": "What does a p-value represent in hypothesis testing?",
    "options": [
      "Probability of observing the data or more extreme, assuming null hypothesis is true",
      "Probability the null hypothesis is true",
      "Sample size required",
      "The alternative hypothesis"
    ],
    "correctAnswer": "Probability of observing the data or more extreme, assuming null hypothesis is true",
    "explanation": "P-value quantifies evidence against the null hypothesis."
  },
  {
    "id": 140,
    "question": "When performing feature selection, why is it important to only use the training data?",
    "options": [
      "To avoid information leakage and preserve unbiased evaluation",
      "Because test data contains missing values",
      "To reduce computation time",
      "It's not important"
    ],
    "correctAnswer": "To avoid information leakage and preserve unbiased evaluation",
    "explanation": "Using test data for feature selection contaminates validation."
  },
  {
    "id": 141,
    "question": "In survival analysis, what does a Kaplan-Meier curve show?",
    "options": [
      "Estimated probability of survival over time",
      "Hazard function",
      "Regression coefficients",
      "Confusion matrix"
    ],
    "correctAnswer": "Estimated probability of survival over time",
    "explanation": "KM plots survival function as a step function over observed time."
  },
  {
    "id": 142,
    "question": "What is the main purpose of outlier detection in data analysis?",
    "options": [
      "To improve data quality and prevent skewed model results",
      "To find missing values",
      "To increase dataset size",
      "To remove all large values"
    ],
    "correctAnswer": "To improve data quality and prevent skewed model results",
    "explanation": "Outliers can distort statistical measures and model performance."
  },
  {
    "id": 143,
    "question": "Which of the following is NOT a principle of GDPR?",
    "options": [
      "Purpose limitation",
      "Data minimization",
      "Indefinite data storage",
      "Integrity and confidentiality"
    ],
    "correctAnswer": "Indefinite data storage",
    "explanation": "GDPR requires storage limitation, not indefinite retention."
  }
]
